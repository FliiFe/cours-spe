\ifsolo
    ~

    \vspace{1cm}

    \begin{center}
        \textbf{\LARGE Variables aléatoires discrètes} \\[1em]
    \end{center}
    \tableofcontents
\else
    \chapter{Variables aléatoires discrètes}

    \minitoc
\fi
\thispagestyle{empty}

\section{Tribu}
\subsection{Définition}

Dans tout le chapitre, $\Omega$ désigne un ensemble non vide.

\begin{dfn}
    Un ensemble $\mathcal A$ de parties de $\Omega$ est une \textbf{tribu}\index{tribu} si \begin{itemize}
        \item $ \mathcal A$ est stable par passage au complémentaire
        \item $\emptyset \in \mathcal A$
        \item $ \mathcal A$ est stable par union dénombrable
    \end{itemize}
    On dit alors que $(\Omega, \mathcal A)$ est un \textbf{espace probabilisable}\index{espace probabilisable}  et les éléments de $\mathcal A$ sont appelés  \textbf{événements} \index{evenement@événement}
\end{dfn}


\subsection{Propriétés ensemblistes}

\begin{prop}
    Soit $(\Omega, \mathcal A)$ un espace probabilisable. Si $(A_n)\in \mathcal A^{\N}$ alors \[
        \bigcap_{n\in\N}A_n \in \mathcal A
    \]
\end{prop}

\begin{proof}
    C'est une union dénombrable de complémentaires
\end{proof}

\begin{notation}[HP]
    \[
        \underline{\lim}A_n=\bigcup_{n\in\N} \left( \bigcap_{m\geq n} A_m \right) \qquad \qquad \overline{\lim} A_n=\bigcap_{n\in\N} \left( \bigcup_{m\geq n}A_m \right) 
    \]
\end{notation}

\subsection{Opérations sur les tribus}

Soit $(\mathcal A_i)_{i\in I}$ une famille de tribus. L'ensemble \[
    \bigcap_{i\in I}\mathcal A_i
\]
est une tribu (facile).

\begin{rem}
    On définit ainsi la notion de tribu engendrée: la tribu engendrée par $\mathcal E\subset \mathcal P(\Omega)$ est l'intersection de toutes les tribus contenant $\mathcal E$.
\end{rem}

\begin{dfn}
    Soit $(\Omega, \mathcal A)$ un espace probabilisable. \begin{itemize}
        \item $A,B\in \mathcal A$ sont \textbf{incompatible} si $A \cap B=\emptyset$
        \item Pour $A\in \mathcal A$, on appelle  \textbf{événement contraire} l'événement $A^c$
        \item On dit que $(A_i)_{i\in I} \in  \mathcal A^I$ est un \textbf{système complet d'événements}\index{système complet d'événements, SCE} si et seulement si $(A_i)_{i\in I}$ partitionne $\Omega$.
    \end{itemize}
\end{dfn}

\section{Espace probabilisé}

\begin{dfn}
    Soit $(\Omega, \mathcal A)$ un espace probabilisable. On appelle \textbf{probabilité}\index{probabilité} sur $(\Omega, \mathcal A)$ une application $\P:\mathcal A \to  [0, 1]$ telle que \begin{itemize}
        \item $\P(\Omega)=1$
        \item $\P$ est $\sigma$-additive, c'est-à-dire que pour toute suite $(A_i)$ d'événements deux à deux incompatibles, \[
                \P \left( \bigcup_{n\in\N}A_n \right) =\sum_{n\geq 0}\P(A_n)
        \]
    \end{itemize}
    Si $\P$ convient, on dira que $(\Omega, \mathcal A, \P)$ est un \textbf{espace probabilisé}\index{espace probabilisé}.
\end{dfn}

\begin{rem}
    \begin{itemize}
        \item La suite constante égale à $\emptyset$ donne $\P(\emptyset)=0$.
        \item Si $A$ et $B$ sont incompatibles, alors $\P(A\cup B)=\P(A)+\P(B)$ 
        \item $\P(A^c)=\P(A\cup A^c)-\P(A)=1-\P(A)$
        \item $A\subset B \implies P(B)=P(A)+P(B\setminus A)\geq P(A)$
    \end{itemize}
\end{rem}

\begin{exo}[Inégalité d'Edith Kosmanek\index{Kosmanek (inégalité de -- )}]
    Soit $(\Omega, \mathcal A, \P)$ un espace probabilisé, $A, B$ des événements. Montrer que \[
        |\P(A\cap B)-\P(A)\P(B)|\leq \frac{1}{4}
    \]
\end{exo}

\begin{proof}[Résolution]
    $(A\cap B, A\cap B^c, A^c\cap B, A^c\cap B^c)$ est un SCE et un peu de calcul donne \[
        \P(A\cap B)-\P(A)\P(B)=\P(A\cap B)\P(A^c\cap B^c)-\P(A^c\cap B)\P(A\cap B^c)
    \]
    Puis si $a,b\geq 0$ sont tels que $a+b\leq 1$, on a $ab=\sqrt{ab}^2\leq \left( \frac{a+b}{2} \right) ^2\leq \frac{1}{4}$ donc les deux produits sont $\leq \frac{1}{4}$, ce qui conclut.
\end{proof}

\begin{exo}
    $(\Omega, \mathcal A, \P)$ probabilisé, $A, B \in \mathcal A$. Montrer que $|\P(A)-\P(B)| \leq \P(A\Delta B)$
\end{exo}

\section{Propriétés élémentaires des probabilités}

\begin{thm}[Continuité croissante\index{Continuité croissante (probabilités)}]
    \Hyp $(\Omega, \mathcal A, \P)$ probabilisé, $(A_n)_{n\in \N}$ suite croissante d'événements
    \Conc \[
        \P\left(\bigcup_{n\in \N}A_n \right)=\lim_{n \to \infty} \P(A_n).
    \]
\end{thm}

\begin{proof} Par $\sigma$-additivité, en posant $A_{-1}=\emptyset$, on a
    \[
        \P\left( \bigcup_{n\in N} A_n \right) =\sum_{n\geq 0}\P(A_n\setminus A_{n-1})= \lim_{n \to \infty} \sum_{k=0}^{n} \underbrace{\P(A_k\setminus A_{k-1})}_{=\P(A_k)-\P(A_{k-1})}=\lim_{n \to \infty} \P(A_n).
    \]
\end{proof}

\begin{thm}[Continuité décroissante]
    \Hyp $(\Omega, \mathcal A, \P)$ probabilisé, $(A_n)_{n\in \N}$ suite décroissante d'événements
    \Conc \[
        \P\left(\bigcap_{n\in \N}A_n \right)=\lim_{n \to \infty} \P(A_n).
    \]
\end{thm}

\begin{proof}
    C'est la continuité croissante en passant au complémentaire.
\end{proof}

\begin{thm}[Sous-additivité]
    \Hyp $(\Omega, \mathcal A, \P)$ espace probabilisé, $(A_n)$ suite d'événements
    \Conc Avec la convention qu'une somme de série divergente à terme général positif vaut $+\infty$, \[
        \P\left( \bigcup_{n \in  \N}A_n  \right) \leq \sum_{n=0}^{+\infty} \P(A_n).
    \] 
\end{thm}

\begin{proof}
    On note \[
    X_n=\bigcup_{k\in \N}A_k 
    \] 
    de sorte que $(X_n)$ est une suite croissante d'événements. Pour deux événements $A\subset B$, on a \[
        \P(A\cup B)=\P(A\cup(B\setminus A))=\P(A)+\P(B\setminus A)\leq \P(A)+\P(B)
    \] 
    et en itérant, on trouve \[
        \forall n \in  \N, \qquad \P(X_n)\leq \sum_{k=0}^{n} \P(A_i)
    \] 
    donc \[
        \lim_{n \to \infty} \P(X_n) = \P\left( \bigcup_{n\in \N} A_n \right) \leq \sum_{n=0}^{+\infty} \P(A_n)
    \] 
\end{proof}

\begin{rem}
    Un événement $A\in \mathcal A$ est dit \textbf{négligeable} si $\P(A)=0$. Si $(A_n)$ est une suite d'événements négligeables, alors \[
        \P(\bigcup_{n\in \N}A_n )\leq \sum_{n=0}^{+\infty} \P(A_n)=0
    \] 
\end{rem}

\subsection{Formule de Poincaré}

Soit $(\Omega, \mathcal A, \P)$ un espace probabilisé, $A_1, \cdots, A_n \in  \mathcal A$. On va montrer que \[
    \P(A_1\cup \cdots \cup A_n)=\sum_{1\leq i_1\leq n}P(A_{i_1})-\sum_{1\leq i_1<i_2\leq n}P(A_{i_1}\cap A_{i_2}) +\cdots +(-1)^{n-1}\sum_{1\leq i_1<\cdots <i_n\leq n}P(A_{i_1}\cap \cdots \cap A_{i_n})
\] 
On remarque pour cela \[
    \1_{(A_1\cup \cdots \cup A_n)^c}=1-\1_{A_1\cup \cdots \cup A_n}=\1_{A_1^c\cap \cdots \cap A_n^c}=\1_{A_1^c}\times \cdots \times \1_{A_n^c}=(1-\1_{A_1})\times \cdots \times (1-\1_{A_n})
\]
donc en développant, \[
    \1_{(A_1\cup \cdots \cup A_n)^c} = 1-\sum_{i=1}^n\1_{A_i}-\sum_{i_1<i_2}\1_{A_{i_1}\cap A_{i_2}}+\cdots +(-1)^{n-1}\sum_{i_1<\cdots <i_n}\1_{A_{i_1}\cap\cdots\cap A_{i_n}}
\]
Or (on le verra), $\E(\1_A)=\P(A)$ et $\E$ est linéaire, ce qui conclut.

\begin{ex}
    On place $r$ boules dans $n$ cases. Calculer la probabilité qu'aucune case ne soit vide. On note $A_i$ l'événement "La case n°$i$ est vide" et $B=A_1^c\cap \cdots \cap A_n^c$. On cherche $\P(B)$. On a \[
        \forall k \in  \llbracket 1, n\rrbracket, \qquad \P(A_{i_1}\cap \cdots \cap A_{i_k})= \left( 1-\frac{k}{n} \right) ^r.
    \] 
    Puis, \begin{align*}
        \P(B^c)=1-\P(B)&=\sum_{1\leq i_1\leq n} \left( 1-\frac{1}{n} \right) ^r-\sum_{i_1<i_2} \left( 1-\frac{2}{n} \right) ^r+\cdots +(-1)^{n-1} \sum_{i_1<\cdots <i_n} \left( 1-\frac{n}{n} \right) ^r\\
                       &=\sum_{k=0}^n(-1)^k\binom nk \left( 1-\frac{k}{n} \right) ^r
    \end{align*}
\end{ex}

\section{Probabilité conditionnelle}

\begin{dfn}
    Soit $(\Omega, \mathcal A, \P)$ un espace probabilisé et $B\in \mathcal A$ tel que $\P(B)>0$. On appelle probabilité de $A \in \mathcal A$ sachant $B$ le nombre  \[
        \P_B(A)=\P(A|B)\defeq \frac{\P(A\cap B)}{P(B)}
    \] 
\end{dfn}

\begin{prop}
    \Hyp $(\Omega, \mathcal A, \P)$ un espace probabilisé, $A_1, \cdots , A_n \in  \mathcal A$ tels que $\P(A_1 \cap \cdots \cap A_n)>0$
    \Conc \[
        \P(A_1\cap \cdots \cap A_n)=\P(A_1)\P(A_2|A_1)\P(A_3|A_1\cap A_2)\cdots \P(A_n|A_1\cap\cdots\cap A_{n-1})
    \] 
\end{prop}

\begin{proof}
    La seule difficulté est de montrer que les probabilités utilisées existent. C'est le cas car \[
        \forall i\leq n, \qquad 0<\P(A_1\cap\cdots\cap A_n)\leq \P(A_1\cap \cdots \cap A_i)
    \] 
\end{proof}

\begin{ex}
    On se donne un sac dans lequel il y a une boule blanche et une boule noire. À chaque tour, on tire une boule et on en remet deux de la même couleur dans le sac. Quelle est la probabilité de tirer $n$ boules blanches lors des $n$ premiers tirages ?

    On note $A_n$ l'événement cherché et: \begin{itemize}
        \item $ \P(A_1)=\frac{1}{2}$
        \item $\P(A_n|A_{n-1})=\dfrac n{n+1}$
        \item \begin{align*}
                \P(A_n)&=\P(A_1\cap \cdots \cap A_n) \\ &= \P(A_1)\cdot \P(A_2|A_1)\cdots \P(A_n|A_1\cap\cdots \cap A_{n-1}) \\ &=\P(A_1)\P(A_2|A_1)\cdots \P(A_n|A_{n-1}) \\ &= \frac{1}{2} \times \frac{2}{3} \times \cdots \times \frac{n}{n+1}\\&=\frac{1}{n+1}
        \end{align*}
    \end{itemize}
\end{ex}

\begin{ex}[Monty Hall]
    Dans le jeu télévisé \emph{Let's make a deal}, un candidat doit choisir une porte parmi trois. Derrière deux d'entre elles, il y a une chèvre, et derrière la troisième il y a une voiture. On note $X$ la variable aléatoire qui correspond au premier choix. Une fois le choix effectué, le présentateur révèle une chèvre parmi les portes non choisies, et le candidat a l'occasion de changer son choix. On note alors $Y$ la variable aléatoire qui vaut $0$ si le candidat ne change pas son choix et $1$ s'il le change. Le candidat a-t-il intérêt à changer son choix ?

    On suppose que la porte gagnante est la porte numéro $1$ et on note $A$ l'événement qui correspond à une victoire du candidat. On a \begin{itemize}
        \item $\P(A|X=1,Y=1)=1$
        \item $\P(A|X=2,Y=1)=0$
        \item $\P(A|X=3,Y=1)=0$
        \item $\P(A|X=1,Y=0)=0$
        \item $\P(A|X=2,Y=0)=1$
        \item $\P(A|X=3,Y=0)=1$
    \end{itemize}
    Donc \[
        \P(A|Y=1)=\P(A|X=1,Y=1)+\P(A|X=2,Y=1)\P(X=2)+\P(A|X=3,Y=1)\P(X=3)=\frac{2}{3}
    \]
    Donc le candidat a intérêt à changer son choix.
\end{ex}

\begin{defprop}[Trace]
    \Hyp $(\Omega, \mathcal A, \P)$ est un espace probabilisé, $A\in \mathcal A$ un événement tel que $\P(A)>0$
    \begin{concenum}
        \item $\mathcal A_A\defeq\{A\cap B, \quad B\in \mathcal A\}$ est une tribu de $A$
        \item $(A,\mathcal A_A, \P_A)$ est un espace probabilisé, avec {\begin{align*}
                \P_A:\mathcal A_A  &\longrightarrow [0,1] \\
                B &\longmapsto \frac{\P(B)}{\P(A)}
        \end{align*}}
    \end{concenum}
\end{defprop}

\begin{prop}
    \Hyp $(\Omega, \mathcal A, \P)$ est un espace probabilisé, $A\in \mathcal A$ un événement tel que $\P(A)>0$
    \Conc $(\Omega, \mathcal A, \P_A)$ est un espace probabilisé avec { \begin{align*}
            \P_A: \mathcal A &\longrightarrow [0,1] \\
            B &\longmapsto \frac{\P(A\cap B)}{\P(A)}
    \end{align*} }
\end{prop}

\begin{thmdef}
    \Hyp $(\Omega, \mathcal A, \P)$ espace probabilisé
    \begin{concenum}
    \item On dira que $(A_n)\in \mathcal A^{\N}$ est un \textbf{système complet d'événements}\index{système complet d'événements} si \begin{itemize}
        \item $ \forall n\in \N,\quad A_n \neq \emptyset$
        \item Les $A_i$ sont deux à deux incompatibles
        \item $\bigcup_{i \in  \N}A_i  =\Omega$ 
    \end{itemize}
    \item Pour tout $A\in \mathcal A$ on a dans ce cas \[
            \P(A)=\sum_{n \in  \N} \P(A\cap A_n)=\sum_{n \in  \N} \P_{A_n}(A)\P(A_n)
    \] 
    en convenant que si $\P(A_n)=0$ alors $\P(A_n)\P_{A_n}(A)=0$
    \end{concenum}
\end{thmdef}

\begin{proof}
    C'est la $\sigma$-additivité.
\end{proof}

\begin{rem}
    On peut se dispenser de l'hypothèse $A_i\neq \emptyset$, et on peut se contenter de  $\P(\bigcup A_n )=1$ au lieu de $ \bigcup A_n=\Omega $. On parle alors de système pseudo-complet ou presque-complet.
\end{rem}

\section{Formule de Bayes}

\begin{thm}[Bayes]
    \Hyp $(\Omega, \mathcal A, \P)$ espace probabilisé
    \begin{concenum}
        \item Si $A,B\in \mathcal A$ sont tels que $\P(A), \P(B)>0$, alors \[
            \P(B|A)=\frac{\P(A|B)\P(B)}{\P(A)}
        \] 
    \item Si $(A_n)\in  \mathcal A^{\N}$ est un SCE, $B\in \mathcal A$ est tel que $\P(B)>0$, alors \[
            \P_B(A_i)=\frac{\P_{A_i}(B)\P(A_i)}{\sum_{n=0}^{+\infty} \P_{A_n}(B)\P(A_n)}
    \] 
    \end{concenum}
\end{thm}

\section{Germes de probabilités}

\begin{prop}[Germe de probabilité\index{germe de probabilité}]
    \Hyp $\Omega=\{x_i, \quad i \in  \N\}$, $\mathcal A=\mathcal P(\Omega)$ et $(p_i)_{i \in \N} \in (\R^+)^{\N}$ telle que $\sum p_i=1$
    \Conc Il existe une unique probabilité $\P$ sur $(\Omega, \mathcal A)$ telle que $\forall i \in  \N,\quad \P(\{x_i\})=p_i$, et elle est donnée par \[
        \forall X \in  \mathcal A,\quad \P(X)=\sum_{\substack{i \in  \N\\x_i\in X}}p_i
    \] 
\end{prop}

\begin{proof}
    Unicité facile, existence facile.
\end{proof}

\section{Variables aléatoires discrètes}

\begin{dfn}
    Soit $(\Omega, \mathcal A, \P)$ un espace probabilisé et $E$ un ensemble. On appelle \textbf{variable aléatoire discrète}\index{variable aléatoire discrète} à valeurs dans $E$ une application $X:\Omega \to  E$ telle que \begin{itemize}
        \item $X(\Omega)$ est fini ou dénombrable
        \item  $ \forall x \in  E,\quad X^{-1}(\{x\} )\in  \mathcal A$
    \end{itemize}
\end{dfn}

\begin{ex}
    $A\in \mathcal A,\quad \1_A$ est une v.a.d
\end{ex}

\begin{rem}
    Si $E$ est dénombrable, alors $E$ s'écri t  $\{x_n,\quad n\in \N\} $ avec les $x_n$ deux à deux distincts. Si  $X:\Omega \to  E$ est une v.a.d alors \begin{itemize}
        \item $A_n=X^{-1}(\{x_n\} )$. Les $(A_n)_n$ forment un SCE (ou un quasi-SCE)
        \item $p_n=\P(A_n)$ définit un germe de probabilité
        \item Une probabilité sur $(E, \mathcal P(E))$ est donnée par \[
                \forall B\subset E,\quad \sum_{\substack{n\geq 0\\ x_n\in  B}}p_n
        \] 
        et on a \[
            [X\in B]=\bigcup_{\substack{n\geq 0\\x_n\in  B}}X^{-1}(\{x_n\} )\in  \mathcal A 
        \] 
        donc \[
            \P(X\in  B)=\sum_{\substack{n\geq 0\\x_n\in B}}\P(A_n)=\P_\star (B)
        \] 
    \end{itemize}
    On a ainsi une probabilité sur $(E, \mathcal P(E))$ à partir de $(\Omega, \mathcal A, \P)$ sans connaître $\Omega$. On a seulement besoin de connaître les $p_n$ (la loi de $X$)
\end{rem}

\begin{thm}
    \Hyp $E=\{x_n, \quad n\in \N\} $, les $x_n$ deux à deux distincts, $(p_n)_{n\in \N}\in (\R^+)^{\N}, \quad \sum p_n=1$
    \Conc Il existe $\Omega$, une tribu $\mathcal A$ de $\Omega$, $\P$ une probabilité telle que $(\Omega, \mathcal A,\P)$ est un espace probabilisé et $X:\Omega\to E$ est une v.a.d satisfaisant $\P(X=x_n)=p_n$
\end{thm}

\begin{proof}
    Admis(e) mais facile ($\Omega=E, \mathcal A=\mathcal P(E)$)
\end{proof}

\section{Indépendance}

\begin{dfn}
    $(\Omega, \mathcal A, \P)$ un espace probabilisé. Deux événements $A,B\in \mathcal A$ sont dits \textbf{indépendants}\index{evenements independants@événements indépendants} si et seulement si $\P(A\cap B)=\P(A)\P(B)$. Si $\P(B)\neq 0$, c'est équivalent à $\P(A|B)=\P(A)$
\end{dfn}

\begin{dfn}
    Soit $(\Omega, \mathcal A, \P)$ un espace probabilisé. \begin{itemize}
        \item Si $X_1, \cdots, X_n$ sont des v.a.d sur $\Omega$, $E_i=X_i(\Omega)$, on dira que $X_1, \cdots,X_n$ sont \textbf{mutuellement indépendantes}\index{indépendance mutuelle} si \[
                \forall (A_1,\cdots,A_n)\in \mathcal P(E_1)\times \cdots \times \mathcal P(E_n), \qquad \P(X_1\in  A_1,\cdots,X_n\in A_n)=P(X_1\in A_1)\cdots \P(X_n\in A_n)
        \] ou de manière équivalente \[
        \forall (x_1,\cdots,x_n)\in E_1\times \cdots \times E_n, \qquad \P(X_1=x_1,\cdots,X_n=x_n)=\P(X_1=x_1)\cdots \P(X_n=x_n)
        \] 
    \item Si $X, Y$ sont des v.a.d indépendantes, on note $X\indep Y$
    \end{itemize}
\end{dfn}
